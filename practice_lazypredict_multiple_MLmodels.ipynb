{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "be5e7a1a7278c138e277e90b019db4961154c731"
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "\n",
    "import os\n",
    "from operator import itemgetter    \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import funcsigs\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import preprocessing\n",
    "from sklearn.impute import SimpleImputer\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler, LabelEncoder, MinMaxScaler, OneHotEncoder, LabelBinarizer\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, mean_absolute_error\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, RandomizedSearchCV, KFold, cross_val_predict, StratifiedKFold, train_test_split, learning_curve, ShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection, preprocessing\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, RandomizedSearchCV,KFold, cross_val_predict, StratifiedKFold, train_test_split, learning_curve, ShuffleSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, ShuffleSplit\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, f1_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score, auc\n",
    "from funcsigs import signature\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from mlxtend.plotting import plot_learning_curves\n",
    "from mlxtend.preprocessing import shuffle_arrays_unison\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import models, regularizers, layers, optimizers, losses, metrics\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import math\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "\n",
    "from statsmodels.formula import api\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d624986c6d662b3dec980c593981fb913cb00c01"
   },
   "outputs": [],
   "source": [
    "# read in the data\n",
    "\n",
    "df = pd.read_excel(r\"dataset.xlsx\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set target and features\n",
    "\n",
    "target = 'COPD_Diagnose_ja_nein'\n",
    "features = [i for i in df.columns if i not in [target]]\n",
    "\n",
    "# make a copy of the original data\n",
    "\n",
    "original_df = df.copy(deep=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show what are in the work space.\n",
    "\n",
    "dir()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1fce3fd763d30cf516d00815bb386cd95cea14ec",
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# display some data information \n",
    "\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1fce3fd763d30cf516d00815bb386cd95cea14ec",
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# display some data information \n",
    "\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1fce3fd763d30cf516d00815bb386cd95cea14ec",
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# display some data information \n",
    "\n",
    "print(df.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check the number of values for all columns \n",
    "\n",
    "df.nunique().sort_values()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# figure out numerical and categorical features\n",
    "\n",
    "nu = df[features].nunique().sort_values()\n",
    "nf = []; \n",
    "cf = []; \n",
    "nnf = 0; \n",
    "ncf = 0; \n",
    "\n",
    "for i in range(df[features].shape[1]):\n",
    "    if nu.values[i]<=16: \n",
    "        cf.append(nu.index[i])\n",
    "    else: nf.append(nu.index[i])\n",
    "\n",
    "print('\\n\\033[1mInference:\\033[0m The Datset has {} numerical and {} categorical features.'.format(len(nf),len(cf)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set how many numerical features and categorical features.\n",
    "\n",
    "Nnf = 13\n",
    "Ncf = 6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count plot for categorical features\n",
    "\n",
    "print('\\033[1mVisualising Categorical Features:'.center(100))\n",
    "\n",
    "fig, axs = plt.subplots(nrows = 2, ncols = 3)\n",
    "ax = axs.flatten()\n",
    "for i in range(len(cf)):\n",
    "    if df[cf[i]].nunique()<=16:\n",
    "        sns.countplot(x = cf[i], data = df, ax = ax[i])\n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution plot for numerical features\n",
    "\n",
    "print('\\033[1mNumeric Features Distribution'.center(130))\n",
    "\n",
    "fig, axs = plt.subplots(nrows = 5, ncols = 3)\n",
    "ax = axs.flatten()\n",
    "for i in range(len(nf)):\n",
    "    sns.distplot(df[nf[i]], ax = ax[i], hist_kws=dict(edgecolor=\"black\", linewidth=2), bins=10)\n",
    "plt.tight_layout()\n",
    "ax[13].set_visible(False)\n",
    "ax[14].set_visible(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot for numerical features\n",
    "\n",
    "fig, axs = plt.subplots(nrows = 5, ncols = 3)\n",
    "ax = axs.flatten()\n",
    "for i in range(len(nf)):\n",
    "    df.boxplot(nf[i], ax = ax[i])\n",
    "plt.tight_layout()\n",
    "ax[13].set_visible(False)\n",
    "ax[14].set_visible(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pairplots for all features \n",
    "\n",
    "# g = sns.pairplot(df)\n",
    "# plt.title('Pairplots for all the Feature')\n",
    "# g.map_upper(sns.kdeplot, levels=4, color=\".2\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the number of Null values in each feature\n",
    "\n",
    "nvc = pd.DataFrame(df.isnull().sum().sort_values(), columns=['Total Null Values'])\n",
    "nvc['Percentage'] = round(nvc['Total Null Values']/df.shape[0],3)*100\n",
    "print(nvc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review a few rows of the data\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the null values in a few features by the most frequent value in that column. \n",
    "\n",
    "df['Raceethnicity'].fillna(df['Raceethnicity'].mode()[0],inplace=True)\n",
    "df['Sex'].fillna(df['Sex'].mode()[0],inplace=True)\n",
    "df['Dentatestatus'].fillna(df['Dentatestatus'].mode()[0],inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the null values in a some features by mean value.  \n",
    "\n",
    "col_to_be_imputed = ['AgeatinterviewScreener', 'PovertyIncomeRatiounimputedincome', 'Pulseratebeatsminage5years','OverallaverageK1systolicBPage5', 'OverallaverageK5diastolicBPage5', 'Bodymassindex','Upperquadrantperiodontalassessments','Lowerquadrantperiodontalassessments','SumofpermanentDMFSduetodisease','SumofpermanentDFMSduetoanycause','SumofpermanentDFMSduetoanycause','SumofpermanentDFS','SumofpermanentDMFTduetodisease','SumofpermanentDMFTduetoanycause','Bleeding_Percentage','Furcation_SUM', 'MAL']\n",
    "for item in col_to_be_imputed:\n",
    "    df[item].fillna(df[item].mean(),inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder categrical features by LabelEncoder. \n",
    "\n",
    "le = LabelEncoder()\n",
    "df['Raceethnicity'] = le.fit_transform(df['Raceethnicity'])\n",
    "df['Sex'] = le.fit_transform(df['Sex'])\n",
    "df['Dentatestatus'] = le.fit_transform(df['Dentatestatus'])\n",
    "\n",
    "# convert other features values from float to int\n",
    "\n",
    "df['AgeatinterviewScreener'] = df['AgeatinterviewScreener'].astype(int)\n",
    "df['PovertyIncomeRatiounimputedincome'] = df['PovertyIncomeRatiounimputedincome'].astype(int)\n",
    "df['Pulseratebeatsminage5years'] = df['Pulseratebeatsminage5years'].astype(int)\n",
    "df['OverallaverageK1systolicBPage5'] = df['OverallaverageK1systolicBPage5'].astype(int)\n",
    "df['OverallaverageK5diastolicBPage5'] = df['OverallaverageK5diastolicBPage5'].astype(int)\n",
    "df['Bodymassindex'] = df['Bodymassindex'].astype(int)\n",
    "df['Upperquadrantperiodontalassessments'] = df['Upperquadrantperiodontalassessments'].astype(int)\n",
    "df['Lowerquadrantperiodontalassessments'] = df['Lowerquadrantperiodontalassessments'].astype(int)\n",
    "df['SumofpermanentDMFSduetodisease'] = df['SumofpermanentDMFSduetodisease'].astype(int)\n",
    "df['SumofpermanentDFMSduetoanycause'] = df['SumofpermanentDFMSduetoanycause'].astype(int)\n",
    "df['SumofpermanentDFMSduetoanycause'] = df['SumofpermanentDFMSduetoanycause'].astype(int)\n",
    "df['SumofpermanentDFS'] = df['SumofpermanentDFS'].astype(int)\n",
    "df['SumofpermanentDMFTduetodisease'] = df['SumofpermanentDMFTduetodisease'].astype(int)\n",
    "df['SumofpermanentDMFTduetoanycause'] = df['SumofpermanentDMFTduetoanycause'].astype(int)\n",
    "df['Bleeding_Percentage'] = df['Bleeding_Percentage'].astype(int)\n",
    "df['Furcation_SUM'] = df['Furcation_SUM'].astype(int)\n",
    "df['MAL'] = df['MAL'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display information of all features. \n",
    "\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove some useless features. \n",
    "\n",
    "df_feat = df.drop(['Raceethnicity','Sex','Dentatestatus','COPD_Diagnose_ja_nein'],axis=1)\n",
    "\n",
    "# get labels for each sample.\n",
    "\n",
    "target =  pd.get_dummies(df[['COPD_Diagnose_ja_nein']],drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get labels for each categrical feature. \n",
    "\n",
    "dummies = pd.get_dummies(df[['Raceethnicity','Sex','Dentatestatus', ]],drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display a few rows of the useful features. \n",
    "\n",
    "df_feat.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize all features data by sklearn StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df_feat)\n",
    "df_scaled = scaler.transform(df_feat)\n",
    "df_scaled = pd.DataFrame(df_scaled,columns=df_feat.columns[:19])\n",
    "df_preprocessed = pd.concat([df_scaled,dummies,target], axis=1)\n",
    "df_preprocessed.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show number of features and number of samples\n",
    "\n",
    "print('\\n\\033[1mInference:\\033[0m The Datset consists of {} features & {} samples.'.format(df_preprocessed.shape[1], df_preprocessed.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see summarize of feature values\n",
    "\n",
    "df_preprocessed.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "798b9834d32ba534e5aca36d5763b9624fe00565"
   },
   "outputs": [],
   "source": [
    "# set y (values to be predicted), and X (feature values)\n",
    "\n",
    "y = df_preprocessed['COPD_Diagnose_ja_nein']\n",
    "X = df_preprocessed.drop('COPD_Diagnose_ja_nein', axis = 1)\n",
    "\n",
    "print(\"y - Labels\", y.shape)\n",
    "print(\"X - N Label N id \", X.shape)\n",
    "print(X.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "60be44d230f432f3f087f15a238feb21deb68bbf"
   },
   "outputs": [],
   "source": [
    "# review the shapes of data frames\n",
    "\n",
    "print(df_preprocessed.shape)\n",
    "print(X.shape)\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "aefe400392c73d77e55bf9f2410e7b725df2e77c"
   },
   "outputs": [],
   "source": [
    "# separate data to Tain or Test.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)\n",
    "print ('X_train: ', X_train.shape)\n",
    "print ('X_test: ', X_test.shape)\n",
    "print ('y_train: ', y_train.shape)\n",
    "print ('y_test: ', y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check a few of y values\n",
    "\n",
    "y.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run multiple machine learning models by lazypredict package.\n",
    "\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "\n",
    "clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None)\n",
    "models, predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
    "\n",
    "models\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "30231eece09b4e58137f7de92a1edff1ce67d1eb6dc3e77c83046d0c2c0004f0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
